---
title: "Regresion_lineal_multiple"
author: "Nelson Sarmiento","Nayeli Ramon", "Valeria Ulloa"
format: pdf
editor: visual
---

# Aprendizaje estadÃ­stico

En general, la relaciÃ³n de los valores de entrada y salida se puede escribir de la sifuiente forma:

$$ Y = f(X) + âˆŠ $$

Esto se centra en la estimaciÃ³n de f desde varios enfoques. Existen 2 razones principales para estimar f:

### PredicciÃ³n

En este punto es necesario entender que un conjunto de entradas (x) estÃ¡ facilmente disponible mientras que las salidas (y) no son faciles de obtener ya que existe la posibilidad del error, si tomamos que el tÃ©rmino de error es un promedio 0 pordemos predecir siguiendo la fÃ³rmula:

$$ Y' = f'(X) $$

f' : estimaciÃ³n para f.

Y': predicciÃ³n resultante para Y.

Por lo general, dentro de esta fÃ³rmula la forma de f' no es tomada en cuenta siempre que produzca las predicciones precisas para Y.

La precisiÃ³n de Y' depende de 2 errores el reducible y el irreducible.

-   Reducible: Este error se puede minimizar usando la tÃ©cnica de aprendizaje estadÃ­stico, mÃ¡s apropiada para estimar f.
-   Irreducible: Este error se debe a que Y tambiÃ©n en una funciÃ³n de âˆŠ.

### Inferencia

Dentro de la inferencia es necesario tomar en cuenta que nos interesa saber la forma exacta de f'. Esto se debe a que nos interesa conocer la asociaciÃ³n entre cada variable y probabilidad a diferencia de la predicciÃ³n que se interesa mÃ¡s en la precisiÃ³n del resultado.

## Estimar f

Una forma de estimar f es aplicar el mÃ©todo de aprendizaje estadÃ­stico a los datos de entrenamiento, estos mÃ©todos se pueden caracterizar como paramÃ©tricos y no paramÃ©tricos:

-   ParamÃ©tricos: se basa en modelos de 2 pasos, hacer la suposiciÃ³n de la forma funcional y utilizar el procedimeinto que use los datos de entrenamiento para ajustar el modelo. Este enfoque reduce el problema de estimar f a estimar un conjunto de parÃ¡metros.

    nota: Una desventaja de este enfoque es que el modelo por lo general no coincide con la verdadera forma de f.

-   No paramÃ©tricos: No se hace supociones de la forma funcional de f, se busca una estimaciÃ³n de f que se acerque lo mejor posible a los puntos de datos sin ser demasiado ondulado. Evita la posibilidad que el modelo no se ajuste a los datos.

    nota: Una desventaja es que se requiere un gran numero de observaciones para obtener la estimaciÃ³n precisas de f.

# RegresiÃ³n lineal

Es un mÃ©todo de aprendizaje supervisado, se puede lograr predecir una respuesta cuantitativa, esto, con el objetivo de poder procesar dos o mÃ¡s grupos de datos y encontrar una relaciÃ³n entre ellos.

AsÃ­ tambiÃ©n, la regresiÃ³n lineal se convierte en una herramienta Ãºtil al tener datos con una tendencia lineal de relaciÃ³n logrando cuantificar su relaciÃ³n de interacciÃ³n.

### RegresiÃ³n lineal simple

Es aplicada para predecir una respuesta cuantitativa *Y* a partir de una variable predictiva Ãºnica *X,* esto suponiendo que existe una relaciÃ³n casi lineal entre X y Y. Esto se puede representar en una ecuaciÃ³n como:

$$Y â‰ˆ ğ›½0 + ğ›½1X + âˆŠ$$

La ecuaciÃ³n se representarÃ­a como: "RegresiÃ³n de Y sobre X", en donde ğ›½0+ğ›½1 son parÃ¡metros desconocidos que representan la intersecciÃ³n y la pendiente de los parÃ¡metros. Una vez utilizados datos de entrenamiento para estimar ğ›½0+ğ›½1 se podrÃ¡ realiza una predicciÃ³n de datos futuros.

### EstimaciÃ³n de coeficientes ğ›½0+ğ›½1

El objetivo principal es obtener valores pertenecientes a cada uno de los coeficientes, tal que, se logre obtener o describir un modelo lineal, esto se logra mediante la representaciÃ³n de "pares de observaciones" en las cuales se obtengan una medida de X y una medida de Y, eso con el objetivo de tener estimaciones para los coeficientes ğ›½0, ğ›½1 tal que el modelo se ajuste a los datos disponibles hasta encontrar una intersecciÃ³n ğ›½0 y una pendiente ğ›½1, esto se lo puede lograr con el criterio de mÃ­nimos cuadrados. Se muestra un ejemplo de la relaciÃ³n lineal entre las ventas de una empresa y los gastos de publicidad en TV.

imagen

Es importante considerar el nivel de error en la aproximaciÃ³n, el cual determina la posible variaciÃ³n en el eje Y que hace que los datos no tengan un carÃ¡cter lineal. Esto define la lÃ­nea de regresiÃ³n de la poblaciÃ³n. Aplicando la estrategia de mÃ­nimos cuadrados podemos obtener una nueva lÃ­nea basada en los datos observados.

imagen

En la figura de la derecha se observa en color rojo la lÃ­nea real de aproximaciÃ³n, mientras en color negro la lÃ­nea de mÃ­nimos cuadrados en base a las observaciones, mientras que en la derecha se observan lÃ­neas basadas en mÃ­nimos cuadrados calculadas mediante observaciones aleatorias, estas estimaciones no se alejan demasiado de la regresiÃ³n lineal de la poblaciÃ³n (lÃ­nea roja).

Como conclusiÃ³n la regresiÃ³n lineal simple es un enfoque Ãºtil para predecir una respuesta sobre la base de una Ãºnica variable predictora.

### RegresiÃ³n lineal mÃºltiple

A diferencia de la regresiÃ³n lineal simple, en la realidad existe mÃ¡s de un predictor, por ello, en vez de realizar varias regresiones lineales simples en donde se sesgan varios datos se debe realizar una regresiÃ³n lineal mÃºltiple. Esto se puede representar en una ecuaciÃ³n como:

$$
Y â‰ˆ ğ›½_0 + ğ›½_1X_1 + ğ›½_2X_2+...+ ğ›½_pX_p + âˆŠ
$$

En donde X1, X2 ... Xp con Ã­ndices predictores.

#### EstimaciÃ³n de los coeficientes de regresiÃ³n

Al igual que en la regresiÃ³n lineal simple los coeficientes ğ›½0, ğ›½1 ... ğ›½p son los que deben estimarse y en base a estas estimaciones se pueden llagar a hacer predicciones. Para esta estimaciÃ³n se utiliza el mismo enfoque de mÃ­nimos cuadrados.

Para representar las estimaciones de coeficientes de regresiÃ³n lineal mÃºltiple se lo debe hacer mediante algebra matricial por medio de un paquete estadÃ­stico.

Es necesario responder ciertas preguntas al realizar regresiÃ³n lineal mÃºltiple:

-   **Â¿Existe alguna relaciÃ³n entre la respuesta y los predictores?**

    En este caso se debe plantear una hipÃ³tesis nula en donde ğ›½0, ğ›½1 ... ğ›½p = 0Â y una hipÃ³tesis alternativa, en donde ğ›½0, ğ›½1 ... ğ›½p â‰  0 , aplicando la fÃ³rmula podemos obtener un falor de F en el cual se determina un valor cercano a 1 cuando no hay relaciÃ³n entre la pregunta y la respuesta, mientras que si existiera relaciÃ³n el valor serÃ­a superior a 1.

-   **Decidir sobre variables importantes**

    Al determinar que los predictores si tienen una relaciÃ³n con las peguntas es necesario determinar cuales de ellos establecen esta relaciÃ³n. Para ello, es necesario realizar una selecciÃ³n de variables aplicando el mÃ©todo de Criterio de InformaciÃ³n de Akaike u otro a conveniencia. Estos establecen 3 enfoques clÃ¡sicos:

-   SelecciÃ³n hacia adelante: Implica iniciar con un modelo nulo, se ajustan regresiones lineales simples y se selecciona la variable con carÃ¡cter mas bajo continuando con el ejercicio hasta cumplir con la regla de detenciÃ³n.

-   SelecciÃ³n hacia atrÃ¡s: Se inicia con todas las variables, eliminando la variable con carÃ¡cter mas alto, es decir, la menos significativa estadÃ­sticamente.

-   SelecciÃ³n mixta: es una combinaciÃ³n de selecciÃ³n hacia adelante y hacia atrÃ¡s

imagen

Se observa una grafica de los datos obtenidos, en donde existen 2 predictores y una sola respuesta, esto en un plano 3D.

Al ajustar un modelo a una regresiÃ³n lineal pueden ocurrir varios problemas, entre los cuales estÃ¡n:

-   **No linealidad de las relaciones respuesta-predictor:** Esto conlleva a que todas las conclusiones sean cuestionables y la precisiÃ³n de predicciÃ³n se reducen significativamente, esto se lo puede evitar aplicando los " grÃ¡ficos de residuos"

-   **Valores atÃ­picos:** Estos valores surgen entre una de sus razones por el registro incorrecto de una observaciÃ³n durante la recopilaciÃ³n de datos, asÃ­ mismo se pueden utilizar " grÃ¡ficos de residuos" para determinar el valor atÃ­pico y retÃ­ralo, esto mejorarÃ¡ la ecuaciÃ³n de linealidad obtenida.

-   **Puntos de apalancamiento:** son observaciones que se encuentran fuera del conglomerado de datos, esto produce que la ecuaciÃ³n de linealidad tienda a flexionarse de acuerdo al nivel de apalancamiento de la observaciÃ³n, mientras mas alejada este la observaciÃ³n del conjunto de observaciones mayor grado de apalancamiento habrÃ¡.

imagen

Como se observa en la figura de la izquierda, la observaciÃ³n 41 presenta un mayor grado de apalancamiento con respecto a la observaciÃ³n 20, asÃ­ mismo, en la figura central se evidencia una observaciÃ³n inusual fuera del grupo de datos, esto produce un alto apalancamiento; mientras que en la figura de la derecha se observa un punto 41 con un grado muy alto de apalancamiento.
